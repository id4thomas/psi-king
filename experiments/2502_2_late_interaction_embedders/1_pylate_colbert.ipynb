{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pylate package ColBERT implementation\n",
    "* https://github.com/lightonai/pylate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from config import settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notable ColBERT Args\n",
    "\n",
    "```\n",
    "prompts\n",
    "    A dictionary with prompts for the model. The key is the prompt name, the value is the prompt text. The prompt text will be prepended before any text to encode. For example:\n",
    "    `{\"query\": \"query: \", \"passage\": \"passage: \"}` or `{\"clustering\": \"Identify the main category based on the\n",
    "    titles in \"}`.\n",
    "embedding_size\n",
    "    The output size of the projection layer. Default to 128.\n",
    "query_prefix\n",
    "    Prefix to add to the queries.\n",
    "document_prefix\n",
    "    Prefix to add to the documents.\n",
    "add_special_tokens\n",
    "    Add the prefix to the inputs.\n",
    "truncation\n",
    "    Truncate the inputs to the encoder max lengths or use sliding window encoding.\n",
    "query_length\n",
    "    The length of the query to truncate/pad to with mask tokens. If set, will override the config value. Default to 32.\n",
    "document_length\n",
    "    The max length of the document to truncate. If set, will override the config value. Default to 180.\n",
    "attend_to_expansion_tokens\n",
    "    Whether to attend to the expansion tokens in the attention layers model. If False, the original tokens will\n",
    "    not only at tend to the expansion tokens, only the expansion tokens will attend to the original tokens. Default\n",
    "    is False (as in the original ColBERT codebase).\n",
    "skiplist_words\n",
    "    A list of words to skip from the documents scoring (note that these tokens are used for encoding and are only skipped during the scoring). Default is the list of string.punctuation.\n",
    "model_kwargs : dict, optional\n",
    "    Additional model configuration parameters to be passed to the Huggingface Transformers model\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyLate model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from pylate.models import ColBERT\n",
    "\n",
    "model_dir = os.path.join(settings.model_weight_dir, \"late_interaction/ModernBERT-Korean-ColBERT-preview-v1\")\n",
    "\n",
    "# https://github.com/lightonai/pylate/blob/fe115ff8bd93351670d516859952804ced1198f7/pylate/models/colbert.py#L35\n",
    "model = ColBERT(\n",
    "    model_name_or_path=model_dir,\n",
    "    embedding_size=1024, # defaults to 128 if not set\n",
    "    document_length=None, # don't set\n",
    "    device=\"mps\",\n",
    "    prompts={\"query\": \"query: \", \"passage\": \"passage: \"} # input prefix text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d29d1d0371944193abac9848c2d2d994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding documents (bs=32):   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "texts = [\n",
    "    \"예시 문서 1번 입니다.\",\n",
    "    \"안녕하세요 제 이름은 송영록 입니다\"\n",
    "]\n",
    "\n",
    "passage_embeddings = model.encode(\n",
    "    sentences=texts,\n",
    "    batch_size=32,\n",
    "    is_query=False,\n",
    "    show_progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, (19, 128), numpy.ndarray)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(passage_embeddings), passage_embeddings[0].shape, type(passage_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19, 128), (29, 128))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Different Shape for each passage (depends on passage length)\n",
    "passage_embeddings[0].shape, passage_embeddings[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docling",
   "language": "python",
   "name": "docling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# allganize-RAG-Evaluation data + multimodal hybrid search\n",
    "## Methodology\n",
    "1. Read PDF files with `Reader`\n",
    "    * Try `DoclingPDFReader` with `PDF2ImageReader` as fallback\n",
    "2. Chunk `Document` into single-node `Document`\n",
    "3. Embed chunk `Document` instances\n",
    "    * dense: `Visualized_BGE`\n",
    "    * sparse\n",
    "4. Insert into `QdrantSingleHybridVectorStore` vector store\n",
    "5. Test retrieval with queries\n",
    "\n",
    "## Setting\n",
    "* parser:\n",
    "    * IBM [Docling](https://github.com/DS4SD/docling) v2.22.0\n",
    "    * docling-v2 pdf parser backend\n",
    "* dense embedding model: `baai/bge-visualized` (bge-m3 weight)\n",
    "    * https://huggingface.co/BAAI/bge-visualized\n",
    "* data: real-life pdf files from `allganize-RAG-Evaluation-Dataset-KO`\n",
    "    * https://huggingface.co/datasets/allganize/RAG-Evaluation-Dataset-KO\n",
    "    * use 10 'finance' domain PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import time\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import jsonlines\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from config import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "core_src_dir = os.path.join(parent_dir, \"src/psiking\")\n",
    "sys.path.append(core_src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Core Schemas\n",
    "from core.base.schema import Document, TextNode, ImageNode, TableNode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read Data\n",
    "* 10 pdf files\n",
    "* try conversion with docling -> use pdf2image as fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.datamodel.pipeline_options import (\n",
    "    PdfPipelineOptions,\n",
    "    PictureDescriptionApiOptions\n",
    ")\n",
    "from core.reader.pdf.docling_reader import DoclingPDFReader\n",
    "\n",
    "format_options = PdfPipelineOptions()\n",
    "format_options.images_scale = 1.5\n",
    "format_options.generate_page_images = True\n",
    "format_options.generate_picture_images = True\n",
    "\n",
    "format_options.do_ocr = False\n",
    "format_options.do_table_structure = True\n",
    "\n",
    "# Image description\n",
    "print(\"VLM MODEL:\", settings.vlm_model)\n",
    "\n",
    "# Use VLM for image description (ImageNode.text)\n",
    "image_description_options = PictureDescriptionApiOptions(\n",
    "    url=f\"{settings.vlm_base_url}/v1/chat/completions\",\n",
    "    params=dict(\n",
    "        model=settings.vlm_model,\n",
    "        seed=42,\n",
    "        max_completion_tokens=512,\n",
    "        temperature=0.9\n",
    "    ),\n",
    "    prompt=\"이미지에 대해 3줄 정도로 자세히 설명해 주세요. 이미지에 정보가 없다면 설명 텍스트를 작성하지 않습니다\",\n",
    "    timeout=90,\n",
    "    bitmap_area_threshold=0.05 # 5% of page area\n",
    ")\n",
    "format_options.do_picture_description = True\n",
    "format_options.picture_description_options = image_description_options\n",
    "\n",
    "docling_reader = DoclingPDFReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.reader import PDF2ImageReader\n",
    "\n",
    "# testing on macOS, provide poppler path manually\n",
    "poppler_path = \"/opt/homebrew/Cellar/poppler/25.01.0/bin\"\n",
    "pdf2img_reader = PDF2ImageReader(poppler_path=poppler_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num files: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['★2019 제1회 증시콘서트 자료집_최종★.pdf',\n",
       " '240409(보도자료) 금융위 핀테크 투자 생태계 활성화 나선다.pdf',\n",
       " '2024년 3월_3. 향후 통화신용정책 방향.pdf',\n",
       " '133178946057443204_WP22-05.pdf',\n",
       " '240130(보도자료) 지방은행의 시중은행 전환시 인가방식 및 절차.pdf',\n",
       " '130292099630937500_KIFVIP2013-10.pdf',\n",
       " '2024년 3월_2. 통화신용정책 운영.pdf',\n",
       " '[별첨] 지방은행의 시중은행 전환시 인가방식 및 절차.pdf',\n",
       " '240320(보도자료) 금융권의 상생금융 추진현황.pdf',\n",
       " '한-호주 퇴직연금 포럼_책자(최종).pdf']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PDF File directory\n",
    "pdf_dir = os.path.join(settings.data_dir, \"allganize-RAG-Evaluation-Dataset-KO/finance\")\n",
    "pdf_fnames =[x for x in os.listdir(pdf_dir) if x.endswith(\".pdf\")]\n",
    "print(\"num files:\", len(pdf_fnames))\n",
    "pdf_fnames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:51, 17.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'core.base.schema.TextNode'>\n",
      "<class 'core.base.schema.TextNode'>\n",
      "<class 'core.base.schema.TableNode'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert pages to image\n",
    "documents = []\n",
    "docling_failed_fnames = []\n",
    "pdf2img_failed_fnames = []\n",
    "for doc_i, fname in tqdm(enumerate(pdf_fnames[:3])):\n",
    "    file_path = os.path.join(pdf_dir, fname)\n",
    "    extra_info = {\n",
    "        \"source_id\": f\"allganize-RAG-Evaluation-Dataset-KO/finance/{doc_i}\", # arbitrary id\n",
    "        \"domain\": \"finance\",\n",
    "        \"source_file\": fname\n",
    "    }\n",
    "    try:\n",
    "        document = docling_reader.run(\n",
    "            file_path,\n",
    "            extra_info=extra_info\n",
    "        )\n",
    "        documents.append(document)\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(\"[DOCLING READER] failed {} - {}\".format(fname, str(e)))\n",
    "        docling_failed_fnames.append(fname)\n",
    "    \n",
    "    try:\n",
    "        document = pdf2img_reader.run(\n",
    "            file_path,\n",
    "            extra_info=extra_info\n",
    "        )\n",
    "        documents.append(document)\n",
    "    except Exception as e:\n",
    "        print(\"[PDF2IMG READER] failed {} - {}\".format(fname, str(e)))\n",
    "        pdf2img_failed_fnames.append(fname)\n",
    "    \n",
    "for node in document.nodes[:3]:\n",
    "    print(type(node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source_id': 'allganize-RAG-Evaluation-Dataset-KO/finance/2',\n",
       " 'domain': 'finance',\n",
       " 'source_file': '2024년 3월_3. 향후 통화신용정책 방향.pdf'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = document.nodes[0].image\n",
    "\n",
    "# # Crop to half\n",
    "# width, height = image.size\n",
    "# left_half = image.crop((0, 0, width, height//2))\n",
    "# left_half"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Process Document into Chunks\n",
    "1. merge text nodes with `TextNodeMerger`\n",
    "2. split texts into chunks with `LangchainRecursiveCharacterTextSplitter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.processor.document.text_merger import TextNodeMerger\n",
    "# Split Documents page-level\n",
    "merger = TextNodeMerger()\n",
    "\n",
    "merged_documents = []\n",
    "for document in documents:\n",
    "    merged_document = merger.run(document)\n",
    "    merged_documents.append(merged_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextNode(id_='d8480416-eacf-429d-819e-cd0087504758', metadata={'page_no': 1}, text_type=<TextType.PLAIN: 'plain'>, label=<TextLabel.PLAIN: 'plain'>, resource=MediaResource(data=None, text='증권사 리서치센터장, 자산운용사 대표와 함께하는 제1회 증시 콘서트\\n2019 하반기 증시 대전망\\n|\\xa0일\\xa0시\\xa0| 2019.\\xa07.\\xa02\\xa0(화)\\xa014:30\\n|\\xa0장\\xa0소\\xa0| 금융투자협회\\xa03층\\xa0불스홀', path=None, url=None, mimetype=None))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merged_documents[0]\n",
    "merged_documents[0].nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258\n"
     ]
    }
   ],
   "source": [
    "# 3. Run Splitter\n",
    "from core.splitter.text.langchain_text_splitters import LangchainRecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = LangchainRecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1024,\n",
    "    chunk_overlap = 128\n",
    ")\n",
    "\n",
    "chunks = []\n",
    "for document in merged_documents:\n",
    "    document_chunks = []\n",
    "    source_id = document.id_\n",
    "    for i, node in enumerate(document.nodes):\n",
    "        # Run Splitter\n",
    "        if isinstance(node, TextNode):\n",
    "            try:\n",
    "                split_nodes = splitter.run(node)\n",
    "            except Exception as e:\n",
    "                print(i, node)\n",
    "                print(str(e))\n",
    "                raise e\n",
    "        else:\n",
    "            split_nodes = [node]\n",
    "        \n",
    "        # Create New Document\n",
    "        for split_node in split_nodes:\n",
    "            # Each Document contains single node\n",
    "            chunk = Document(\n",
    "                nodes=[split_node],\n",
    "                metadata={\n",
    "                    \"source_id\": source_id,\n",
    "                    \"domain\": document.metadata[\"domain\"],\n",
    "                    \"source_file\": document.metadata['source_file'],\n",
    "                }\n",
    "            )\n",
    "        document_chunks.append(chunk)\n",
    "    chunks.extend(document_chunks)\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Format Text (Prepare Embedding Input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.formatter.document.simple import SimpleTextOnlyFormatter\n",
    "\n",
    "# use default templates\n",
    "formatter = SimpleTextOnlyFormatter()\n",
    "formatted_texts = formatter.run(chunks)\n",
    "\n",
    "def select_embedding_input_idxs(texts: str, min_length: int = 20):\n",
    "    return [i for i, x in enumerate(texts) if len(x.strip())>min_length]\n",
    "\n",
    "embedding_input_idxs = select_embedding_input_idxs(\n",
    "    texts=formatted_texts,\n",
    "    min_length=20\n",
    ")\n",
    "print(len(embedding_input_idxs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Embed Using ColPali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-1. Dense Embedding VisualizedBGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/docling/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model\n"
     ]
    }
   ],
   "source": [
    "## Load Model\n",
    "import torch\n",
    "from visual_bge.modeling import Visualized_BGE\n",
    "\n",
    "# Load Colpali engine\n",
    "bge_m3_model_dir = os.path.join(\n",
    "    settings.model_weight_dir, \"bge-m3\"\n",
    ")\n",
    "visualized_model_dir = os.path.join(\n",
    "    settings.model_weight_dir, \"baai-bge-visualized/Visualized_m3.pth\"\n",
    ")\n",
    "\n",
    "dense_embedding_model = Visualized_BGE(\n",
    "    model_name_bge = bge_m3_model_dir,\n",
    "    model_weight= visualized_model_dir\n",
    ")\n",
    "dense_embedding_model.eval()\n",
    "print(\"Loaded Dense Embedding Model\")\n",
    "dense_embedding_model.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.embedder.flagembedding import (\n",
    "    VisualizedBGEInput, \n",
    "    LocalVisualizedBGEEmbedder\n",
    ")\n",
    "dense_embedder = LocalVisualizedBGEEmbedder(\n",
    "    model=dense_embedding_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_visualized_bge_input(chunk: Document):\n",
    "    # Single \n",
    "    node = chunk.nodes[0]\n",
    "    if isinstance(node, TextNode):\n",
    "        return VisualizedBGEInput(\n",
    "            text=node.text\n",
    "        )\n",
    "    elif isinstance(node, ImageNode) or isinstance(node, TableNode):\n",
    "        return VisualizedBGEInput(\n",
    "            text=\"[Caption] {} [Text] {}\".format(\n",
    "                node.caption, node.text\n",
    "            ),\n",
    "            image=node.image\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Unknown node type error {}\".format(type(node)))\n",
    "visualized_bge_inputs = [prepare_visualized_bge_input(x) for x in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [02:48<00:00,  4.81s/it]\n",
      "100%|██████████| 30/30 [00:42<00:00,  1.41s/it]\n"
     ]
    }
   ],
   "source": [
    "dense_embeddings = dense_embedder.run(visualized_bge_inputs, batch_size = 4, disable_tqdm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "# (num_chunks, seq_len, embedding_dim)\n",
    "print(len(dense_embeddings))\n",
    "print(len(dense_embeddings[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-2. Sparse Embedding\n",
    "* Embed using BM42 Sparse embedder model\n",
    "    * https://huggingface.co/Qdrant/all_miniLM_L6_v2_with_attentions\n",
    "\n",
    "### Loading model from pre-downloaded directory\n",
    "* Load model using 'specific model path'\n",
    "    * specific_model_path (Optional[str], optional): The specific path to the onnx model dir if it should be imported from somewhere else\n",
    "    * download_model method skips download phase (available > v0.5.1 )\n",
    "        * https://github.com/qdrant/fastembed/blob/a931f143ef3543234bc9d8d0c305496c67199972/fastembed/common/model_management.py#L367\n",
    "    * build from source with commit `a931f143ef3543234bc9d8d0c305496c67199972`\n",
    "* cache_dir: cache_dir (str, optional): The path to the cache directory.\n",
    "    Can be set using the `FASTEMBED_CACHE_PATH` env variable.\n",
    "    Defaults to `fastembed_cache` in the system's temp directory.\n",
    "```\n",
    "cd poetry\n",
    "poetry build\n",
    "pip install --force-reinstall fastembed-0.5.1-py3-none-any.whl\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"FASTEMBED_CACHE_PATH\"] = str(os.path.join(os.getcwd(), \"fastembed\"))\n",
    "print(os.environ[\"FASTEMBED_CACHE_PATH\"])\n",
    "sparse_model_dir = os.path.join(settings.model_weight_dir, \"fastembed/sparse/all_miniLM_L6_v2_with_attentions\")\n",
    "os.listdir(sparse_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fastembed model\n",
    "from fastembed import SparseTextEmbedding\n",
    "\n",
    "# test specific_model_path function\n",
    "downloaded_dir = SparseTextEmbedding.download_model(\n",
    "    model={},\n",
    "    cache_dir=os.environ[\"FASTEMBED_CACHE_PATH\"],\n",
    "    specific_model_path=sparse_model_dir,\n",
    ")\n",
    "print(downloaded_dir)\n",
    "\n",
    "sparse_model = SparseTextEmbedding(\n",
    "    model_name=\"Qdrant/bm42-all-minilm-l6-v2-attentions\",\n",
    "    specific_model_path=sparse_model_dir,\n",
    "    cuda=False,\n",
    "    lazy_load=False\n",
    ")\n",
    "\n",
    "test_embeddings = list(sparse_model.embed([\"hi\"]))\n",
    "print(test_embeddings)\n",
    "test_embeddings[0].values.tolist(), test_embeddings[0].indices.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Embedder\n",
    "from core.embedder.fastembed.local_sparse import LocalFastEmbedSparseEmbedder\n",
    "\n",
    "sparse_embedder = LocalFastEmbedSparseEmbedder(\n",
    "    model=sparse_model\n",
    ")\n",
    "\n",
    "sparse_embedding_values, sparse_embedding_indices = sparse_embedder.run(\n",
    "    embedding_inputs, batch_size=256\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Insert into VectorStore\n",
    "* intialize qdrant in-memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from core.storage.vectorstore.qdrant import QdrantSingleHybridVectorStore\n",
    "\n",
    "\n",
    "# initialize client\n",
    "client = QdrantClient(\":memory:\")\n",
    "collection_name = \"allganize-finance\"\n",
    "\n",
    "vector_store = QdrantSingleHybridVectorStore(\n",
    "    collection_name=collection_name,\n",
    "    client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Collection\n",
    "from qdrant_client.http import models\n",
    "\n",
    "# bge-m3 1024 dim\n",
    "dense_embedding_dim=1024\n",
    "dense_vectors_config = models.VectorParams(\n",
    "    size=dense_embedding_dim,\n",
    "    distance=models.Distance.COSINE,\n",
    "    on_disk=True,\n",
    ")\n",
    "\n",
    "# Sparse BM42 Embedding\n",
    "sparse_vectors_config = models.SparseVectorParams(\n",
    "    modifier=models.Modifier.IDF, ## uses indices from bm42 embedder\n",
    ")\n",
    "\n",
    "# Create VectorStore\n",
    "vector_store.create_collection(\n",
    "    dense_vector_config=dense_vectors_config,\n",
    "    sparse_vector_config=sparse_vectors_config,\n",
    "    on_disk_payload=True,\n",
    ")\n",
    "\n",
    "# Create Index\n",
    "vector_store.create_index(\n",
    "    field_name=\"text\",\n",
    "    field_schema=models.TextIndexParams(\n",
    "        type=\"text\",\n",
    "        tokenizer=models.TokenizerType.MULTILINGUAL,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add(\n",
    "    documents=[chunks[x] for x in embedding_input_idxs],\n",
    "    texts=embedding_inputs,\n",
    "    dense_embeddings=dense_embeddings,\n",
    "    sparse_embedding_values=sparse_embedding_values,\n",
    "    sparse_embedding_indices=sparse_embedding_indices,\n",
    "    metadata_keys=[\"source_file\", \"source_id\", \"title\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check collection\n",
    "collection_info = vector_store._client.get_collection(\n",
    "    collection_name=vector_store.collection_name\n",
    ")\n",
    "print(collection_info.model_dump_json(indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6f2b2144-2458-43ef-8674-2a58cd847ffb'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0].id_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = vector_store._client.retrieve(\n",
    "    collection_name=vector_store.collection_name,\n",
    "    ids=[chunks[0].id_],\n",
    "    with_vectors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6f2b2144-2458-43ef-8674-2a58cd847ffb\n",
      "{'source_id': '780f8c46-3ce0-4f03-8939-7c893b65ab1e', 'source_file': '★2019 제1회 증시콘서트 자료집_최종★.pdf'}\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "print(points[0].id)\n",
    "print(points[0].payload)\n",
    "print(len(points[0].vector))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docling",
   "language": "python",
   "name": "docling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

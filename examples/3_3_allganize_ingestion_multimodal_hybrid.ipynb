{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# allganize-RAG-Evaluation data + multimodal hybrid search\n",
    "## Methodology\n",
    "1. Read PDF files with `Reader`\n",
    "    * Try `DoclingPDFReader` with `PDF2ImageReader` as fallback\n",
    "2. Chunk `Document` into single-node `Document`\n",
    "3. Embed chunk `Document` instances\n",
    "    * dense: `Visualized_BGE`\n",
    "    * sparse\n",
    "4. Insert into `QdrantSingleHybridVectorStore` vector store\n",
    "5. Test retrieval with queries\n",
    "\n",
    "## Setting\n",
    "* parser:\n",
    "    * IBM [Docling](https://github.com/DS4SD/docling) v2.22.0\n",
    "    * docling-v2 pdf parser backend\n",
    "* dense embedding model: `baai/bge-visualized` (bge-m3 weight)\n",
    "    * https://huggingface.co/BAAI/bge-visualized\n",
    "* data: real-life pdf files from `allganize-RAG-Evaluation-Dataset-KO`\n",
    "    * https://huggingface.co/datasets/allganize/RAG-Evaluation-Dataset-KO\n",
    "    * use 10 'finance' domain PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import time\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import jsonlines\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from config import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "core_src_dir = os.path.join(parent_dir, \"src/psiking\")\n",
    "sys.path.append(core_src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Core Schemas\n",
    "from core.base.schema import Document, TextNode, ImageNode, TableNode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read Data\n",
    "* 10 pdf files\n",
    "* try conversion with docling -> use pdf2image as fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLM MODEL: Qwen2-VL-72B-Instruct-GPTQ-Int4\n"
     ]
    }
   ],
   "source": [
    "from docling.datamodel.pipeline_options import (\n",
    "    PdfPipelineOptions,\n",
    "    PictureDescriptionApiOptions\n",
    ")\n",
    "from core.reader.pdf.docling_reader import DoclingPDFReader\n",
    "\n",
    "format_options = PdfPipelineOptions()\n",
    "format_options.images_scale = 1.5\n",
    "format_options.generate_page_images = True\n",
    "format_options.generate_picture_images = True\n",
    "\n",
    "format_options.do_ocr = False\n",
    "format_options.do_table_structure = True\n",
    "\n",
    "# Image description\n",
    "print(\"VLM MODEL:\", settings.vlm_model)\n",
    "\n",
    "# Use VLM for image description (ImageNode.text)\n",
    "image_description_options = PictureDescriptionApiOptions(\n",
    "    url=f\"{settings.vlm_base_url}/v1/chat/completions\",\n",
    "    params=dict(\n",
    "        model=settings.vlm_model,\n",
    "        seed=42,\n",
    "        max_completion_tokens=512,\n",
    "        temperature=0.9\n",
    "    ),\n",
    "    prompt=\"이미지에 대해 3줄 정도로 자세히 설명해 주세요. 이미지에 정보가 없다면 설명 텍스트를 작성하지 않습니다\",\n",
    "    timeout=90,\n",
    "    bitmap_area_threshold=0.05 # 5% of page area\n",
    ")\n",
    "format_options.do_picture_description = True\n",
    "format_options.picture_description_options = image_description_options\n",
    "\n",
    "docling_reader = DoclingPDFReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.reader import PDF2ImageReader\n",
    "\n",
    "# testing on macOS, provide poppler path manually\n",
    "poppler_path = \"/opt/homebrew/Cellar/poppler/25.01.0/bin\"\n",
    "pdf2img_reader = PDF2ImageReader(poppler_path=poppler_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num files: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['★2019 제1회 증시콘서트 자료집_최종★.pdf',\n",
       " '240409(보도자료) 금융위 핀테크 투자 생태계 활성화 나선다.pdf',\n",
       " '2024년 3월_3. 향후 통화신용정책 방향.pdf',\n",
       " '133178946057443204_WP22-05.pdf',\n",
       " '240130(보도자료) 지방은행의 시중은행 전환시 인가방식 및 절차.pdf',\n",
       " '130292099630937500_KIFVIP2013-10.pdf',\n",
       " '2024년 3월_2. 통화신용정책 운영.pdf',\n",
       " '[별첨] 지방은행의 시중은행 전환시 인가방식 및 절차.pdf',\n",
       " '240320(보도자료) 금융권의 상생금융 추진현황.pdf',\n",
       " '한-호주 퇴직연금 포럼_책자(최종).pdf']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PDF File directory\n",
    "pdf_dir = os.path.join(settings.data_dir, \"allganize-RAG-Evaluation-Dataset-KO/finance\")\n",
    "pdf_fnames =[x for x in os.listdir(pdf_dir) if x.endswith(\".pdf\")]\n",
    "print(\"num files:\", len(pdf_fnames))\n",
    "pdf_fnames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★2019 제1회 증시콘서트 자료집_최종★.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:27, 27.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240409(보도자료) 금융위 핀테크 투자 생태계 활성화 나선다.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:29, 12.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024년 3월_3. 향후 통화신용정책 방향.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:45, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133178946057443204_WP22-05.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encountered an error during conversion of document 02616dbc4dc47f992b7008e68e4f1d4cb49ccece229e7fad02a38a3470346a63:\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/opt/miniconda3/envs/docling/lib/python3.10/site-packages/docling/pipeline/base_pipeline.py\", line 163, in _build_document\n",
      "    for p in pipeline_pages:  # Must exhaust!\n",
      "\n",
      "  File \"/opt/miniconda3/envs/docling/lib/python3.10/site-packages/docling/pipeline/base_pipeline.py\", line 127, in _apply_on_pages\n",
      "    yield from page_batch\n",
      "\n",
      "  File \"/opt/miniconda3/envs/docling/lib/python3.10/site-packages/docling/models/page_assemble_model.py\", line 60, in __call__\n",
      "    for page in page_batch:\n",
      "\n",
      "  File \"/opt/miniconda3/envs/docling/lib/python3.10/site-packages/docling/models/table_structure_model.py\", line 175, in __call__\n",
      "    yield from page_batch\n",
      "\n",
      "  File \"/opt/miniconda3/envs/docling/lib/python3.10/site-packages/docling/models/layout_model.py\", line 146, in __call__\n",
      "    for page in page_batch:\n",
      "\n",
      "  File \"/opt/miniconda3/envs/docling/lib/python3.10/site-packages/docling/models/easyocr_model.py\", line 124, in __call__\n",
      "    yield from page_batch\n",
      "\n",
      "  File \"/opt/miniconda3/envs/docling/lib/python3.10/site-packages/docling/models/page_preprocessing_model.py\", line 25, in __call__\n",
      "    for page in page_batch:\n",
      "\n",
      "  File \"/opt/miniconda3/envs/docling/lib/python3.10/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 220, in initialize_page\n",
      "    page._backend = conv_res.input._backend.load_page(page.page_no)  # type: ignore\n",
      "\n",
      "  File \"/opt/miniconda3/envs/docling/lib/python3.10/site-packages/docling/backend/docling_parse_v2_backend.py\", line 239, in load_page\n",
      "    return DoclingParseV2PageBackend(\n",
      "\n",
      "  File \"/opt/miniconda3/envs/docling/lib/python3.10/site-packages/docling/backend/docling_parse_v2_backend.py\", line 27, in __init__\n",
      "    parsed_page = parser.parse_pdf_from_key_on_page(document_hash, page_no)\n",
      "\n",
      "RuntimeError: Invalid code point\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DOCLING READER] failed 133178946057443204_WP22-05.pdf - Invalid code point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:55, 12.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240130(보도자료) 지방은행의 시중은행 전환시 인가방식 및 절차.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:58,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130292099630937500_KIFVIP2013-10.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [01:15, 11.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024년 3월_2. 통화신용정책 운영.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [02:38, 35.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[별첨] 지방은행의 시중은행 전환시 인가방식 및 절차.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [02:43, 25.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240320(보도자료) 금융권의 상생금융 추진현황.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [02:46, 18.52s/it]Encountered an error during conversion of document ce014774ce984417127bff298a0e883db7ad2652e7cb66d49bbbb2423cc4176c:\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/opt/miniconda3/envs/docling/lib/python3.10/site-packages/docling/pipeline/base_pipeline.py\", line 163, in _build_document\n",
      "    for p in pipeline_pages:  # Must exhaust!\n",
      "\n",
      "  File \"/opt/miniconda3/envs/docling/lib/python3.10/site-packages/docling/pipeline/base_pipeline.py\", line 127, in _apply_on_pages\n",
      "    yield from page_batch\n",
      "\n",
      "  File \"/opt/miniconda3/envs/docling/lib/python3.10/site-packages/docling/models/page_assemble_model.py\", line 60, in __call__\n",
      "    for page in page_batch:\n",
      "\n",
      "  File \"/opt/miniconda3/envs/docling/lib/python3.10/site-packages/docling/models/table_structure_model.py\", line 175, in __call__\n",
      "    yield from page_batch\n",
      "\n",
      "  File \"/opt/miniconda3/envs/docling/lib/python3.10/site-packages/docling/models/layout_model.py\", line 146, in __call__\n",
      "    for page in page_batch:\n",
      "\n",
      "  File \"/opt/miniconda3/envs/docling/lib/python3.10/site-packages/docling/models/easyocr_model.py\", line 124, in __call__\n",
      "    yield from page_batch\n",
      "\n",
      "  File \"/opt/miniconda3/envs/docling/lib/python3.10/site-packages/docling/models/page_preprocessing_model.py\", line 25, in __call__\n",
      "    for page in page_batch:\n",
      "\n",
      "  File \"/opt/miniconda3/envs/docling/lib/python3.10/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 220, in initialize_page\n",
      "    page._backend = conv_res.input._backend.load_page(page.page_no)  # type: ignore\n",
      "\n",
      "  File \"/opt/miniconda3/envs/docling/lib/python3.10/site-packages/docling/backend/docling_parse_v2_backend.py\", line 239, in load_page\n",
      "    return DoclingParseV2PageBackend(\n",
      "\n",
      "  File \"/opt/miniconda3/envs/docling/lib/python3.10/site-packages/docling/backend/docling_parse_v2_backend.py\", line 27, in __init__\n",
      "    parsed_page = parser.parse_pdf_from_key_on_page(document_hash, page_no)\n",
      "\n",
      "RuntimeError: Invalid code point\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한-호주 퇴직연금 포럼_책자(최종).pdf\n",
      "[DOCLING READER] failed 한-호주 퇴직연금 포럼_책자(최종).pdf - Invalid code point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:52, 17.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'core.base.schema.ImageNode'>\n",
      "<class 'core.base.schema.ImageNode'>\n",
      "<class 'core.base.schema.ImageNode'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert pages to image\n",
    "documents = []\n",
    "docling_failed_fnames = []\n",
    "pdf2img_failed_fnames = []\n",
    "for doc_i, fname in tqdm(enumerate(pdf_fnames)):\n",
    "    file_path = os.path.join(pdf_dir, fname)\n",
    "    print(fname)\n",
    "    extra_info = {\n",
    "        \"source_id\": f\"allganize-RAG-Evaluation-Dataset-KO/finance/{doc_i}\", # arbitrary id\n",
    "        \"domain\": \"finance\",\n",
    "        \"source_file\": fname\n",
    "    }\n",
    "    try:\n",
    "        document = docling_reader.run(\n",
    "            file_path,\n",
    "            extra_info=extra_info\n",
    "        )\n",
    "        documents.append(document)\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(\"[DOCLING READER] failed {} - {}\".format(fname, str(e)))\n",
    "        docling_failed_fnames.append(fname)\n",
    "    \n",
    "    try:\n",
    "        document = pdf2img_reader.run(\n",
    "            file_path,\n",
    "            extra_info=extra_info\n",
    "        )\n",
    "        documents.append(document)\n",
    "    except Exception as e:\n",
    "        print(\"[PDF2IMG READER] failed {} - {}\".format(fname, str(e)))\n",
    "        pdf2img_failed_fnames.append(fname)\n",
    "    \n",
    "for node in document.nodes[:3]:\n",
    "    print(type(node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source_id': 'allganize-RAG-Evaluation-Dataset-KO/finance/9',\n",
       " 'domain': 'finance',\n",
       " 'source_file': '한-호주 퇴직연금 포럼_책자(최종).pdf'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = document.nodes[0].image\n",
    "\n",
    "# # Crop to half\n",
    "# width, height = image.size\n",
    "# left_half = image.crop((0, 0, width, height//2))\n",
    "# left_half"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Process Document into Chunks\n",
    "1. merge text nodes with `TextNodeMerger`\n",
    "2. split texts into chunks with `LangchainRecursiveCharacterTextSplitter`\n",
    "3. filter chunks with min length strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.processor.document.text_merger import TextNodeMerger\n",
    "\n",
    "# Split Documents page-level\n",
    "merger = TextNodeMerger()\n",
    "\n",
    "merged_documents = []\n",
    "for document in documents:\n",
    "    merged_document = merger.run(document)\n",
    "    merged_documents.append(merged_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextNode(id_='2b241214-d411-41e2-8410-c0e88a62ab49', metadata={'page_no': 1}, text_type=<TextType.PLAIN: 'plain'>, label=<TextLabel.PLAIN: 'plain'>, resource=MediaResource(data=None, text='증권사 리서치센터장, 자산운용사 대표와 함께하는 제1회 증시 콘서트\\n2019 하반기 증시 대전망\\n|\\xa0일\\xa0시\\xa0| 2019.\\xa07.\\xa02\\xa0(화)\\xa014:30\\n|\\xa0장\\xa0소\\xa0| 금융투자협회\\xa03층\\xa0불스홀', path=None, url=None, mimetype=None))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merged_documents[0]\n",
    "merged_documents[0].nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6fac7f25-bc33-4842-bbdf-fc1ec7a91274',\n",
       " 'a782bc1c-011d-402b-9ed2-4f2439c6e4e2',\n",
       " '0295a537-4856-4564-81a4-d81e272b0398',\n",
       " 'a602289c-abf7-49d9-b49a-747b65dbeea9',\n",
       " '640081d0-57ad-4b74-b632-769176c21062',\n",
       " 'a738059e-cea4-4fc2-b669-a38458fdb168',\n",
       " '6ec2cb86-a114-4f1b-8c62-c00f32534c75',\n",
       " '62af0f2e-c08b-45db-a017-09bd88f68060',\n",
       " 'dbe3a4a8-5669-41de-aaf9-e9031b174a22',\n",
       " '32c09f9c-d78e-4d39-a8b7-ea646aaf4952']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.id_ for x in merged_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010\n"
     ]
    }
   ],
   "source": [
    "# 3. Run Splitter\n",
    "from core.splitter.text.langchain_text_splitters import LangchainRecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = LangchainRecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1024,\n",
    "    chunk_overlap = 128\n",
    ")\n",
    "\n",
    "min_text_length = 30\n",
    "chunks = []\n",
    "for document in merged_documents:\n",
    "    document_chunks = []\n",
    "    source_id = document.id_\n",
    "    for i, node in enumerate(document.nodes):\n",
    "        # Run Splitter\n",
    "        if isinstance(node, TextNode):\n",
    "            try:\n",
    "                split_nodes = splitter.run(node)\n",
    "            except Exception as e:\n",
    "                print(i, node)\n",
    "                print(str(e))\n",
    "                raise e\n",
    "        else:\n",
    "            split_nodes = [node]\n",
    "        \n",
    "        # Create New Document\n",
    "        for split_node in split_nodes:\n",
    "            ## Filter TextNodes with short lengths\n",
    "            if isinstance(split_node, TextNode) and len(split_node.text.strip())<min_text_length:\n",
    "                continue\n",
    "            \n",
    "            # Each Document contains single node\n",
    "            chunk = Document(\n",
    "                nodes=[split_node],\n",
    "                \n",
    "                metadata={\n",
    "                    \"source_id\": source_id,\n",
    "                    \"domain\": document.metadata[\"domain\"],\n",
    "                    \"source_file\": document.metadata['source_file'],\n",
    "                }\n",
    "            )\n",
    "            document_chunks.append(chunk)\n",
    "    chunks.extend(document_chunks)\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010 1010\n"
     ]
    }
   ],
   "source": [
    "chunk_ids =[x.id_ for x in chunks]\n",
    "print(len(chunk_ids), len(set(chunk_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Embed Using VisualizedBGE + BM42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Text Formatter\n",
    "from core.formatter.document.simple import SimpleTextOnlyFormatter\n",
    "\n",
    "# use default templates\n",
    "text_formatter = SimpleTextOnlyFormatter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1. Dense Embedding VisualizedBGE\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/docling/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Dense Embedding Model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load Model\n",
    "import torch\n",
    "from visual_bge.modeling import Visualized_BGE\n",
    "\n",
    "# Load Colpali engine\n",
    "bge_m3_model_dir = os.path.join(\n",
    "    settings.model_weight_dir, \"bge-m3\"\n",
    ")\n",
    "visualized_model_dir = os.path.join(\n",
    "    settings.model_weight_dir, \"baai-bge-visualized/Visualized_m3.pth\"\n",
    ")\n",
    "\n",
    "dense_embedding_model = Visualized_BGE(\n",
    "    model_name_bge = bge_m3_model_dir,\n",
    "    model_weight= visualized_model_dir\n",
    ")\n",
    "dense_embedding_model.eval()\n",
    "print(\"Loaded Dense Embedding Model\")\n",
    "dense_embedding_model.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.embedder.flagembedding import (\n",
    "    VisualizedBGEInput, \n",
    "    LocalVisualizedBGEEmbedder\n",
    ")\n",
    "dense_embedder = LocalVisualizedBGEEmbedder(\n",
    "    model=dense_embedding_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_visualized_bge_input(text_formatter, chunk: Document):\n",
    "    # Single \n",
    "    formatted_text = text_formatter.run([chunk])[0]\n",
    "    \n",
    "    node = chunk.nodes[0]\n",
    "    if isinstance(node, TextNode):\n",
    "        return VisualizedBGEInput(text=formatted_text)\n",
    "    elif isinstance(node, ImageNode) or isinstance(node, TableNode):\n",
    "        return VisualizedBGEInput(\n",
    "            text=formatted_text,\n",
    "            image=node.image\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Unknown node type error {}\".format(type(node)))\n",
    "    \n",
    "visualized_bge_inputs = [prepare_visualized_bge_input(text_formatter, x) for x in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisualizedBGEInput(text='증권사 리서치센터장, 자산운용사 대표와 함께하는 제1회 증시 콘서트\\n2019 하반기 증시 대전망\\n|\\xa0일\\xa0시\\xa0| 2019.\\xa07.\\xa02\\xa0(화)\\xa014:30\\n|\\xa0장\\xa0소\\xa0| 금융투자협회\\xa03층\\xa0불스홀', image=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualized_bge_inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114/114 [03:12<00:00,  1.69s/it]\n",
      "100%|██████████| 140/140 [03:48<00:00,  1.63s/it]\n"
     ]
    }
   ],
   "source": [
    "dense_embeddings = dense_embedder.run(visualized_bge_inputs, batch_size = 4, disable_tqdm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "# (num_chunks, seq_len, embedding_dim)\n",
    "print(len(dense_embeddings))\n",
    "print(len(dense_embeddings[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2. Sparse Embedding (BM42)\n",
    "* Embed using BM42 Sparse embedder model\n",
    "    * https://huggingface.co/Qdrant/all_miniLM_L6_v2_with_attentions\n",
    "\n",
    "### Loading model from pre-downloaded directory\n",
    "* Load model using 'specific model path'\n",
    "    * specific_model_path (Optional[str], optional): The specific path to the onnx model dir if it should be imported from somewhere else\n",
    "    * download_model method skips download phase (available > v0.5.1 )\n",
    "        * https://github.com/qdrant/fastembed/blob/a931f143ef3543234bc9d8d0c305496c67199972/fastembed/common/model_management.py#L367\n",
    "    * build from source with commit `a931f143ef3543234bc9d8d0c305496c67199972`\n",
    "* cache_dir: cache_dir (str, optional): The path to the cache directory.\n",
    "    Can be set using the `FASTEMBED_CACHE_PATH` env variable.\n",
    "    Defaults to `fastembed_cache` in the system's temp directory.\n",
    "```\n",
    "cd poetry\n",
    "poetry build\n",
    "pip install --force-reinstall fastembed-0.5.1-py3-none-any.whl\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/id4thomas/github/psi-king/examples/fastembed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tokenizer_config.json',\n",
       " 'special_tokens_map.json',\n",
       " 'config.json',\n",
       " 'tokenizer.json',\n",
       " 'README.md',\n",
       " 'vocab.txt',\n",
       " 'model.onnx',\n",
       " '.gitattributes',\n",
       " '.git',\n",
       " 'stopwords.txt']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"FASTEMBED_CACHE_PATH\"] = str(os.path.join(os.getcwd(), \"fastembed\"))\n",
    "print(os.environ[\"FASTEMBED_CACHE_PATH\"])\n",
    "sparse_model_dir = os.path.join(settings.model_weight_dir, \"fastembed/sparse/all_miniLM_L6_v2_with_attentions\")\n",
    "os.listdir(sparse_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/id4thomas/models/fastembed/sparse/all_miniLM_L6_v2_with_attentions\n",
      "[SparseEmbedding(values=array([0.30918342]), indices=array([948991206]))]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.3091834199811786], [948991206])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load fastembed model\n",
    "from fastembed import SparseTextEmbedding\n",
    "\n",
    "# test specific_model_path function\n",
    "downloaded_dir = SparseTextEmbedding.download_model(\n",
    "    model={},\n",
    "    cache_dir=os.environ[\"FASTEMBED_CACHE_PATH\"],\n",
    "    specific_model_path=sparse_model_dir,\n",
    ")\n",
    "print(downloaded_dir)\n",
    "\n",
    "sparse_model = SparseTextEmbedding(\n",
    "    model_name=\"Qdrant/bm42-all-minilm-l6-v2-attentions\",\n",
    "    specific_model_path=sparse_model_dir,\n",
    "    cuda=False,\n",
    "    lazy_load=False\n",
    ")\n",
    "\n",
    "test_embeddings = list(sparse_model.embed([\"hi\"]))\n",
    "print(test_embeddings)\n",
    "test_embeddings[0].values.tolist(), test_embeddings[0].indices.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Embedder\n",
    "from core.embedder.fastembed.local_sparse import LocalFastEmbedSparseEmbedder\n",
    "\n",
    "sparse_embedder = LocalFastEmbedSparseEmbedder(\n",
    "    model=sparse_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sparse_input(text_formatter, chunk: Document):\n",
    "    # Single \n",
    "    formatted_text = text_formatter.run([chunk])[0]\n",
    "    return formatted_text\n",
    "\n",
    "sparse_inputs = [prepare_sparse_input(text_formatter, x) for x in chunks]\n",
    "sparse_embedding_values, sparse_embedding_indices = sparse_embedder.run(\n",
    "    sparse_inputs, batch_size=256\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27762097595534047, 0.2596218248069528, 0.29100913226138186, 0.2296326768039164, 0.11464637476009029]\n",
      "[186075762, 777355938, 1724316797, 214838547, 1558169044]\n"
     ]
    }
   ],
   "source": [
    "print(sparse_embedding_values[0][:5])\n",
    "print(sparse_embedding_indices[0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [x.id_ for x in chunks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make DocumentStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010\n"
     ]
    }
   ],
   "source": [
    "from core.storage.docstore import InMemoryDocumentStore\n",
    "\n",
    "docstore = InMemoryDocumentStore()\n",
    "docstore.add(chunks)\n",
    "print(docstore.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Insert into VectorStore\n",
    "* intialize qdrant in-memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from core.storage.vectorstore.qdrant import QdrantSingleHybridVectorStore\n",
    "\n",
    "\n",
    "# initialize client\n",
    "client = QdrantClient(\":memory:\")\n",
    "collection_name = \"allganize-finance\"\n",
    "\n",
    "vector_store = QdrantSingleHybridVectorStore(\n",
    "    collection_name=collection_name,\n",
    "    client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/id4thomas/github/psi-king/src/psiking/core/storage/vectorstore/qdrant/base.py:110: UserWarning: Payload indexes have no effect in the local Qdrant. Please use server Qdrant if you need payload indexes.\n",
      "  self._client.create_payload_index(\n"
     ]
    }
   ],
   "source": [
    "## Create Collection\n",
    "from qdrant_client.http import models\n",
    "\n",
    "# bge-m3 1024 dim\n",
    "dense_embedding_dim=1024\n",
    "dense_vectors_config = models.VectorParams(\n",
    "    size=dense_embedding_dim,\n",
    "    distance=models.Distance.COSINE,\n",
    "    on_disk=True,\n",
    ")\n",
    "\n",
    "# Sparse BM42 Embedding\n",
    "sparse_vectors_config = models.SparseVectorParams(\n",
    "    modifier=models.Modifier.IDF, ## uses indices from bm42 embedder\n",
    ")\n",
    "\n",
    "# Create VectorStore\n",
    "vector_store.create_collection(\n",
    "    dense_vector_config=dense_vectors_config,\n",
    "    sparse_vector_config=sparse_vectors_config,\n",
    "    on_disk_payload=True,\n",
    ")\n",
    "\n",
    "# Create Index\n",
    "vector_store.create_index(\n",
    "    field_name=\"text\",\n",
    "    field_schema=models.TextIndexParams(\n",
    "        type=\"text\",\n",
    "        tokenizer=models.TokenizerType.MULTILINGUAL,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add(\n",
    "    documents=chunks,\n",
    "    texts=sparse_inputs,\n",
    "    dense_embeddings=dense_embeddings,\n",
    "    sparse_embedding_values=sparse_embedding_values,\n",
    "    sparse_embedding_indices=sparse_embedding_indices,\n",
    "    metadata_keys=[\"source_file\", \"source_id\", \"title\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"status\": \"green\",\n",
      "    \"optimizer_status\": \"ok\",\n",
      "    \"vectors_count\": null,\n",
      "    \"indexed_vectors_count\": 0,\n",
      "    \"points_count\": 1010,\n",
      "    \"segments_count\": 1,\n",
      "    \"config\": {\n",
      "        \"params\": {\n",
      "            \"vectors\": {\n",
      "                \"vector_dense\": {\n",
      "                    \"size\": 1024,\n",
      "                    \"distance\": \"Cosine\",\n",
      "                    \"hnsw_config\": null,\n",
      "                    \"quantization_config\": null,\n",
      "                    \"on_disk\": true,\n",
      "                    \"datatype\": null,\n",
      "                    \"multivector_config\": null\n",
      "                }\n",
      "            },\n",
      "            \"shard_number\": null,\n",
      "            \"sharding_method\": null,\n",
      "            \"replication_factor\": null,\n",
      "            \"write_consistency_factor\": null,\n",
      "            \"read_fan_out_factor\": null,\n",
      "            \"on_disk_payload\": null,\n",
      "            \"sparse_vectors\": {\n",
      "                \"vector_sparse\": {\n",
      "                    \"index\": null,\n",
      "                    \"modifier\": \"idf\"\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"hnsw_config\": {\n",
      "            \"m\": 16,\n",
      "            \"ef_construct\": 100,\n",
      "            \"full_scan_threshold\": 10000,\n",
      "            \"max_indexing_threads\": 0,\n",
      "            \"on_disk\": null,\n",
      "            \"payload_m\": null\n",
      "        },\n",
      "        \"optimizer_config\": {\n",
      "            \"deleted_threshold\": 0.2,\n",
      "            \"vacuum_min_vector_number\": 1000,\n",
      "            \"default_segment_number\": 0,\n",
      "            \"max_segment_size\": null,\n",
      "            \"memmap_threshold\": null,\n",
      "            \"indexing_threshold\": 20000,\n",
      "            \"flush_interval_sec\": 5,\n",
      "            \"max_optimization_threads\": 1\n",
      "        },\n",
      "        \"wal_config\": {\n",
      "            \"wal_capacity_mb\": 32,\n",
      "            \"wal_segments_ahead\": 0\n",
      "        },\n",
      "        \"quantization_config\": null,\n",
      "        \"strict_mode_config\": null\n",
      "    },\n",
      "    \"payload_schema\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# check collection\n",
    "collection_info = vector_store._client.get_collection(\n",
    "    collection_name=vector_store.collection_name\n",
    ")\n",
    "print(collection_info.model_dump_json(indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c0e9699c-a4b2-4498-9886-fffd5fcb7c4f'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0].id_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = vector_store._client.retrieve(\n",
    "    collection_name=vector_store.collection_name,\n",
    "    ids=[chunks[0].id_],\n",
    "    with_vectors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c0e9699c-a4b2-4498-9886-fffd5fcb7c4f\n",
      "{'source_id': '6fac7f25-bc33-4842-bbdf-fc1ec7a91274', 'source_file': '★2019 제1회 증시콘서트 자료집_최종★.pdf'}\n",
      "1024\n",
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(points[0].id)\n",
    "print(points[0].payload)\n",
    "\n",
    "# Dense Vector\n",
    "print(len(points[0].vector['vector_dense']))\n",
    "\n",
    "# Sparse Vector\n",
    "print(len(points[0].vector['vector_sparse'].indices))\n",
    "print(len(points[0].vector['vector_sparse'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Test Retrieval with Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "8 [0.31059375711328135, 0.31304877079908167, 0.19882314306607887, 0.1964898348134671, 0.32203981694197703, 0.3009219191747245, 0.10172041730715874, 0.33753322982893214]\n",
      "8 [1024444394, 1285937098, 693871510, 376689346, 332251539, 1798584096, 1061271926, 1903036828]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Embed Query\n",
    "query = \"시중은행, 지방은행, 인터넷은행의 인가 요건 및 절차에 차이가 있는데 그 차이점은 무엇인가요?\"\n",
    "\n",
    "query_dense_embedding = dense_embedder.run(\n",
    "    [VisualizedBGEInput(text=query)],\n",
    "    batch_size = 4,\n",
    "    disable_tqdm=False\n",
    ")\n",
    "\n",
    "query_sparse_embedding_values, query_sparse_embedding_indices = sparse_embedder.run(\n",
    "    [query], batch_size = 1\n",
    ")\n",
    "\n",
    "print(len(query_dense_embedding[0]))\n",
    "print(len(query_sparse_embedding_values[0]), query_sparse_embedding_values[0])\n",
    "print(len(query_sparse_embedding_indices[0]), query_sparse_embedding_indices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# Hybrid Query\n",
    "results = vector_store.query(\n",
    "    mode=\"hybrid\",\n",
    "    dense_embedding=query_dense_embedding[0],\n",
    "    sparse_embedding_values=query_sparse_embedding_values[0],\n",
    "    sparse_embedding_indices=query_sparse_embedding_indices[0],\n",
    "    limit=10\n",
    ")\n",
    "print(len(results.points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='dcd44cdf-858d-481d-af0c-36f56b5aa29d' version=0 score=0.8333333333333333 payload={'source_id': '62af0f2e-c08b-45db-a017-09bd88f68060', 'source_file': '[별첨] 지방은행의 시중은행 전환시 인가방식 및 절차.pdf'} vector=None shard_key=None order_value=None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'source_id': '62af0f2e-c08b-45db-a017-09bd88f68060',\n",
       " 'source_file': '[별첨] 지방은행의 시중은행 전환시 인가방식 및 절차.pdf'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(results.points[0])\n",
    "results.points[0].payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dcd44cdf-858d-481d-af0c-36f56b5aa29d - score 0.833\n",
      "{'source_id': '62af0f2e-c08b-45db-a017-09bd88f68060', 'domain': 'finance', 'source_file': '[별첨] 지방은행의 시중은행 전환시 인가방식 및 절차.pdf'}\n",
      "<class 'core.base.schema.TextNode'>\n",
      "'- *  (은행법  §8 ➀ )  은행업을 경영하려는 자는 금융위원회의 인가를 받아야 한다.\\n\\t- ㅇ 시중은행전국영업뿐만 아니라 지방은행 및 인터넷은행도 모두 ( ) 동일한 조항제'\n",
      "------------------------------\n",
      "730ab9ca-6ba4-4041-9ae5-189cdee17b79 - score 0.611\n",
      "{'source_id': '640081d0-57ad-4b74-b632-769176c21062', 'domain': 'finance', 'source_file': '240130(보도자료) 지방은행의 시중은행 전환시 인가방식 및 절차.pdf'}\n",
      "<class 'core.base.schema.TextNode'>\n",
      "'금융위원회\\n보도자료\\n보도시점\\n20 2 4 . 1 . 3 1 . ( 수  금\\n)\\n융위  회 의   후\\n(별도공지)\\n배포\\n2024.1.30.(화) 10:00\\n지방은행의 시중은행 전환시'\n",
      "------------------------------\n",
      "81338709-1091-404c-8940-469c22aea391 - score 0.417\n",
      "{'source_id': '62af0f2e-c08b-45db-a017-09bd88f68060', 'domain': 'finance', 'source_file': '[별첨] 지방은행의 시중은행 전환시 인가방식 및 절차.pdf'}\n",
      "<class 'core.base.schema.TextNode'>\n",
      "'나. 검토·결론 : 인가규정인 은행법 제8조에 따라 기존 인가내용을 변경\\n- □ 인가방식에 따라 지방은행 인가에 대한 처리폐업인가 ( ), 종전 법률 관계의 승계여부 등이 상이 할'\n",
      "------------------------------\n",
      "ee332e75-0250-442f-b71e-4624a130bc11 - score 0.393\n",
      "{'source_id': '640081d0-57ad-4b74-b632-769176c21062', 'domain': 'finance', 'source_file': '240130(보도자료) 지방은행의 시중은행 전환시 인가방식 및 절차.pdf'}\n",
      "<class 'core.base.schema.TextNode'>\n",
      "'다만,  현행  은행법령상 지방은행의 시중은행 전환에 관한 명시적인 규정은 없으며,  종전에도  은행  종류의  전환  사례는  없었습니다.  지방은행의  정관 에서  특정지역으로'\n",
      "------------------------------\n",
      "4319d2e6-c485-48fb-9746-cbf5184e8597 - score 0.381\n",
      "{'source_id': '6ec2cb86-a114-4f1b-8c62-c00f32534c75', 'domain': 'finance', 'source_file': '2024년 3월_2. 통화신용정책 운영.pdf'}\n",
      "<class 'core.base.schema.TextNode'>\n",
      "'③ 2023년 미 SVB 사태와의 차이점\\n2023년 미 SVB 사태와 미 CRE발 리스크의 가장 큰 차이점은 전자의 경우 중소 지역은행들에 대한 예 금인출 사태(bank-run)로'\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for point in results.points[:5]:\n",
    "    point_id = point.id\n",
    "    point_chunk = docstore.get([point_id])[0]\n",
    "    print(\"{} - score {:.3f}\".format(point_id, point.score))\n",
    "    print(point_chunk.metadata)\n",
    "    print(type(point_chunk.nodes[0]))\n",
    "    print(repr(point_chunk.nodes[0].text[:100]))\n",
    "    print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# Dense-Only Query\n",
    "results = vector_store.query(\n",
    "    mode=\"dense\",\n",
    "    dense_embedding=query_dense_embedding[0],\n",
    "    limit=100\n",
    ")\n",
    "print(len(results.points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "730ab9ca-6ba4-4041-9ae5-189cdee17b79 - score 0.785\n",
      "{'source_id': '640081d0-57ad-4b74-b632-769176c21062', 'domain': 'finance', 'source_file': '240130(보도자료) 지방은행의 시중은행 전환시 인가방식 및 절차.pdf'}\n",
      "<class 'core.base.schema.TextNode'>\n",
      "'금융위원회\\n보도자료\\n보도시점\\n20 2 4 . 1 . 3 1 . ( 수  금\\n)\\n융위  회 의   후\\n(별도공지)\\n배포\\n2024.1.30.(화) 10:00\\n지방은행의 시중은행 전환시'\n",
      "------------------------------\n",
      "dcd44cdf-858d-481d-af0c-36f56b5aa29d - score 0.784\n",
      "{'source_id': '62af0f2e-c08b-45db-a017-09bd88f68060', 'domain': 'finance', 'source_file': '[별첨] 지방은행의 시중은행 전환시 인가방식 및 절차.pdf'}\n",
      "<class 'core.base.schema.TextNode'>\n",
      "'- *  (은행법  §8 ➀ )  은행업을 경영하려는 자는 금융위원회의 인가를 받아야 한다.\\n\\t- ㅇ 시중은행전국영업뿐만 아니라 지방은행 및 인터넷은행도 모두 ( ) 동일한 조항제'\n",
      "------------------------------\n",
      "ee332e75-0250-442f-b71e-4624a130bc11 - score 0.731\n",
      "{'source_id': '640081d0-57ad-4b74-b632-769176c21062', 'domain': 'finance', 'source_file': '240130(보도자료) 지방은행의 시중은행 전환시 인가방식 및 절차.pdf'}\n",
      "<class 'core.base.schema.TextNode'>\n",
      "'다만,  현행  은행법령상 지방은행의 시중은행 전환에 관한 명시적인 규정은 없으며,  종전에도  은행  종류의  전환  사례는  없었습니다.  지방은행의  정관 에서  특정지역으로'\n",
      "------------------------------\n",
      "d7cb411d-0ae3-42a5-b23c-9f7cae152148 - score 0.714\n",
      "{'source_id': '62af0f2e-c08b-45db-a017-09bd88f68060', 'domain': 'finance', 'source_file': '[별첨] 지방은행의 시중은행 전환시 인가방식 및 절차.pdf'}\n",
      "<class 'core.base.schema.TextNode'>\n",
      "\"Ⅰ .  검토  배경\\n- □ 정부는 은행권 경쟁촉진을 위해 지방은행의 시중은행 전환을 허용하겠다고 발표 * ('23.7.5 일 )\\n- *  '금융당국,  은행업에 공정하고 실효성 \"\n",
      "------------------------------\n",
      "81338709-1091-404c-8940-469c22aea391 - score 0.708\n",
      "{'source_id': '62af0f2e-c08b-45db-a017-09bd88f68060', 'domain': 'finance', 'source_file': '[별첨] 지방은행의 시중은행 전환시 인가방식 및 절차.pdf'}\n",
      "<class 'core.base.schema.TextNode'>\n",
      "'나. 검토·결론 : 인가규정인 은행법 제8조에 따라 기존 인가내용을 변경\\n- □ 인가방식에 따라 지방은행 인가에 대한 처리폐업인가 ( ), 종전 법률 관계의 승계여부 등이 상이 할'\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for point in results.points[:5]:\n",
    "    point_id = point.id\n",
    "    point_chunk = docstore.get([point_id])[0]\n",
    "    print(\"{} - score {:.3f}\".format(point_id, point.score))\n",
    "    print(point_chunk.metadata)\n",
    "    print(type(point_chunk.nodes[0]))\n",
    "    print(repr(point_chunk.nodes[0].text[:100]))\n",
    "    print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse-Only Query\n",
    "results = vector_store.query(\n",
    "    mode=\"sparse\",\n",
    "    sparse_embedding_values=query_sparse_embedding_values[0],\n",
    "    sparse_embedding_indices=query_sparse_embedding_indices[0],\n",
    "    limit=100\n",
    ")\n",
    "print(len(results.points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dcd44cdf-858d-481d-af0c-36f56b5aa29d - score 0.647\n",
      "{'source_id': '62af0f2e-c08b-45db-a017-09bd88f68060', 'domain': 'finance', 'source_file': '[별첨] 지방은행의 시중은행 전환시 인가방식 및 절차.pdf'}\n",
      "<class 'core.base.schema.TextNode'>\n",
      "'- *  (은행법  §8 ➀ )  은행업을 경영하려는 자는 금융위원회의 인가를 받아야 한다.\\n\\t- ㅇ 시중은행전국영업뿐만 아니라 지방은행 및 인터넷은행도 모두 ( ) 동일한 조항제'\n",
      "------------------------------\n",
      "4319d2e6-c485-48fb-9746-cbf5184e8597 - score 0.489\n",
      "{'source_id': '6ec2cb86-a114-4f1b-8c62-c00f32534c75', 'domain': 'finance', 'source_file': '2024년 3월_2. 통화신용정책 운영.pdf'}\n",
      "<class 'core.base.schema.TextNode'>\n",
      "'③ 2023년 미 SVB 사태와의 차이점\\n2023년 미 SVB 사태와 미 CRE발 리스크의 가장 큰 차이점은 전자의 경우 중소 지역은행들에 대한 예 금인출 사태(bank-run)로'\n",
      "------------------------------\n",
      "81338709-1091-404c-8940-469c22aea391 - score 0.475\n",
      "{'source_id': '62af0f2e-c08b-45db-a017-09bd88f68060', 'domain': 'finance', 'source_file': '[별첨] 지방은행의 시중은행 전환시 인가방식 및 절차.pdf'}\n",
      "<class 'core.base.schema.TextNode'>\n",
      "'나. 검토·결론 : 인가규정인 은행법 제8조에 따라 기존 인가내용을 변경\\n- □ 인가방식에 따라 지방은행 인가에 대한 처리폐업인가 ( ), 종전 법률 관계의 승계여부 등이 상이 할'\n",
      "------------------------------\n",
      "83e05161-0d11-40e7-b7f7-7d9838eb3bc9 - score 0.449\n",
      "{'source_id': '6ec2cb86-a114-4f1b-8c62-c00f32534c75', 'domain': 'finance', 'source_file': '2024년 3월_2. 통화신용정책 운영.pdf'}\n",
      "<class 'core.base.schema.TextNode'>\n",
      "'미 은행의 대출자산 중 CRE 대출 2) 이 차지하는 비 중은 은행 규모에 따라 큰 차이가 있다. 2023년 6월 말 현재 자산규모가 1천억 달러 이상인 은행의 경 우  전체  대'\n",
      "------------------------------\n",
      "7e4de4e3-a388-4f05-8a29-97074707f1ea - score 0.387\n",
      "{'source_id': '62af0f2e-c08b-45db-a017-09bd88f68060', 'domain': 'finance', 'source_file': '[별첨] 지방은행의 시중은행 전환시 인가방식 및 절차.pdf'}\n",
      "<class 'core.base.schema.TextNode'>\n",
      "'별 첨\\n지방은행의 시중은행 전환시 인가방식 및 절차\\n2024. 1.\\n금   융    위    원    회 금   융    감    독    원\\n목   차'\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for point in results.points[:5]:\n",
    "    point_id = point.id\n",
    "    point_chunk = docstore.get([point_id])[0]\n",
    "    print(\"{} - score {:.3f}\".format(point_id, point.score))\n",
    "    print(point_chunk.metadata)\n",
    "    print(type(point_chunk.nodes[0]))\n",
    "    print(repr(point_chunk.nodes[0].text[:100]))\n",
    "    print('-'*30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docling",
   "language": "python",
   "name": "docling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

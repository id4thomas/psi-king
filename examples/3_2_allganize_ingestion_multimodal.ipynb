{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# allganize-RAG-Evaluation data + multimodal search\n",
    "## Methodology\n",
    "1. \n",
    "\n",
    "## Env\n",
    "* model: `baai/bge-visualized` (bge-m3 weight)\n",
    "* data: real-life pdf files from `allganize-RAG-Evaluation-Dataset-KO`\n",
    "    * https://huggingface.co/datasets/allganize/RAG-Evaluation-Dataset-KO\n",
    "    * use 10 'finance' domain files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import time\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import jsonlines\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from config import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "core_src_dir = os.path.join(parent_dir, \"src/psiking\")\n",
    "sys.path.append(core_src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Core Schemas\n",
    "from core.base.schema import Document, TextNode, ImageNode, TableNode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read Data\n",
    "* 10 pdf files, convert to image with pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.reader.pdf.docling_reader import DoclingPDFReader\n",
    "\n",
    "reader = DoclingPDFReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num files: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['★2019 제1회 증시콘서트 자료집_최종★.pdf',\n",
       " '240409(보도자료) 금융위 핀테크 투자 생태계 활성화 나선다.pdf',\n",
       " '2024년 3월_3. 향후 통화신용정책 방향.pdf',\n",
       " '133178946057443204_WP22-05.pdf',\n",
       " '240130(보도자료) 지방은행의 시중은행 전환시 인가방식 및 절차.pdf',\n",
       " '130292099630937500_KIFVIP2013-10.pdf',\n",
       " '2024년 3월_2. 통화신용정책 운영.pdf',\n",
       " '[별첨] 지방은행의 시중은행 전환시 인가방식 및 절차.pdf',\n",
       " '240320(보도자료) 금융권의 상생금융 추진현황.pdf',\n",
       " '한-호주 퇴직연금 포럼_책자(최종).pdf']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PDF File directory\n",
    "pdf_dir = os.path.join(settings.data_dir, \"allganize-RAG-Evaluation-Dataset-KO/finance\")\n",
    "pdf_fnames =[x for x in os.listdir(pdf_dir) if x.endswith(\".pdf\")]\n",
    "print(\"num files:\", len(pdf_fnames))\n",
    "pdf_fnames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:51, 17.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'core.base.schema.TextNode'>\n",
      "<class 'core.base.schema.TextNode'>\n",
      "<class 'core.base.schema.TableNode'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert pages to image\n",
    "documents = []\n",
    "failed_fnames = []\n",
    "for doc_i, fname in tqdm(enumerate(pdf_fnames[:3])):\n",
    "    file_path = os.path.join(pdf_dir, fname)\n",
    "    try:\n",
    "        document = reader.run(\n",
    "            file_path,\n",
    "            extra_info = {\n",
    "                \"source_id\": f\"allganize-RAG-Evaluation-Dataset-KO/finance/{doc_i}\", # arbitrary id\n",
    "                \"domain\": \"finance\",\n",
    "                \"source_file\": fname\n",
    "            }\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"[READER] failed {} - {}\".format(fname, str(e)))\n",
    "        failed_fnames.append(fname)\n",
    "        continue\n",
    "    document.nodes = document.nodes\n",
    "    documents.append(document)\n",
    "    \n",
    "for node in document.nodes[:3]:\n",
    "    print(type(node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source_id': 'allganize-RAG-Evaluation-Dataset-KO/finance/2',\n",
       " 'domain': 'finance',\n",
       " 'source_file': '2024년 3월_3. 향후 통화신용정책 방향.pdf'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = document.nodes[0].image\n",
    "\n",
    "# # Crop to half\n",
    "# width, height = image.size\n",
    "# left_half = image.crop((0, 0, width, height//2))\n",
    "# left_half"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Process Document into Chunks\n",
    "1. merge text nodes with `TextNodeMerger`\n",
    "2. split texts into chunks with `LangchainRecursiveCharacterTextSplitter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.processor.document.text_merger import TextNodeMerger\n",
    "# Split Documents page-level\n",
    "merger = TextNodeMerger()\n",
    "\n",
    "merged_documents = []\n",
    "for document in documents:\n",
    "    merged_document = merger.run(document)\n",
    "    merged_documents.append(merged_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextNode(id_='d8480416-eacf-429d-819e-cd0087504758', metadata={'page_no': 1}, text_type=<TextType.PLAIN: 'plain'>, label=<TextLabel.PLAIN: 'plain'>, resource=MediaResource(data=None, text='증권사 리서치센터장, 자산운용사 대표와 함께하는 제1회 증시 콘서트\\n2019 하반기 증시 대전망\\n|\\xa0일\\xa0시\\xa0| 2019.\\xa07.\\xa02\\xa0(화)\\xa014:30\\n|\\xa0장\\xa0소\\xa0| 금융투자협회\\xa03층\\xa0불스홀', path=None, url=None, mimetype=None))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merged_documents[0]\n",
    "merged_documents[0].nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258\n"
     ]
    }
   ],
   "source": [
    "# 3. Run Splitter\n",
    "from core.splitter.text.langchain_text_splitters import LangchainRecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = LangchainRecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1024,\n",
    "    chunk_overlap = 128\n",
    ")\n",
    "\n",
    "chunks = []\n",
    "for document in merged_documents:\n",
    "    document_chunks = []\n",
    "    source_id = document.id_\n",
    "    for i, node in enumerate(document.nodes):\n",
    "        # Run Splitter\n",
    "        if isinstance(node, TextNode):\n",
    "            try:\n",
    "                split_nodes = splitter.run(node)\n",
    "            except Exception as e:\n",
    "                print(i, node)\n",
    "                print(str(e))\n",
    "                raise e\n",
    "        else:\n",
    "            split_nodes = [node]\n",
    "        \n",
    "        # Create New Document\n",
    "        for split_node in split_nodes:\n",
    "            # Each Document contains single node\n",
    "            chunk = Document(\n",
    "                nodes=[split_node],\n",
    "                metadata={\n",
    "                    \"source_id\": source_id,\n",
    "                    \"domain\": document.metadata[\"domain\"],\n",
    "                    \"source_file\": document.metadata['source_file'],\n",
    "                }\n",
    "            )\n",
    "        document_chunks.append(chunk)\n",
    "    chunks.extend(document_chunks)\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Embed Using ColPali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/docling/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model\n"
     ]
    }
   ],
   "source": [
    "## Load Model\n",
    "import torch\n",
    "from visual_bge.modeling import Visualized_BGE\n",
    "\n",
    "# Load Colpali engine\n",
    "bge_m3_model_dir = os.path.join(\n",
    "    settings.model_weight_dir, \"bge-m3\"\n",
    ")\n",
    "visualized_model_dir = os.path.join(\n",
    "    settings.model_weight_dir, \"baai-bge-visualized/Visualized_m3.pth\"\n",
    ")\n",
    "\n",
    "model = Visualized_BGE(\n",
    "    model_name_bge = bge_m3_model_dir,\n",
    "    model_weight= visualized_model_dir\n",
    ")\n",
    "model.eval()\n",
    "print(\"Loaded Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.embedder.flagembedding import (\n",
    "    VisualizedBGEInput, \n",
    "    LocalVisualizedBGEEmbedder\n",
    ")\n",
    "embedder = LocalVisualizedBGEEmbedder(\n",
    "    model=model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_embedding_input(chunk: Document):\n",
    "    # Single \n",
    "    node = chunk.nodes[0]\n",
    "    if isinstance(node, TextNode):\n",
    "        return VisualizedBGEInput(\n",
    "            text=node.text\n",
    "        )\n",
    "    elif isinstance(node, ImageNode) or isinstance(node, TableNode):\n",
    "        return VisualizedBGEInput(\n",
    "            text=\"{} {}\".format(\n",
    "                node.caption, node.text\n",
    "            ),\n",
    "            image=node.image\n",
    "        )\n",
    "        \n",
    "inputs = [prepare_embedding_input(x) for x in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [02:48<00:00,  4.81s/it]\n",
      "100%|██████████| 30/30 [00:42<00:00,  1.41s/it]\n"
     ]
    }
   ],
   "source": [
    "embeddings = embedder.run(inputs, batch_size = 4, disable_tqdm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "# (num_chunks, seq_len, embedding_dim)\n",
    "print(len(embeddings))\n",
    "print(len(embeddings[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Insert into VectorStore\n",
    "* intialize qdrant in-memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from core.storage.vectorstore.qdrant import QdrantSingleVectorStore\n",
    "\n",
    "# initialize client\n",
    "client = QdrantClient(\":memory:\")\n",
    "collection_name = \"allganize-finance\"\n",
    "\n",
    "vector_store = QdrantSingleVectorStore(\n",
    "    collection_name=collection_name,\n",
    "    client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.http import models\n",
    "\n",
    "embedding_dim = 1024\n",
    "\n",
    "vector_store.create_collection(\n",
    "    on_disk_payload=True,  # store the payload on disk\n",
    "    vectors_config = models.VectorParams(\n",
    "        size=embedding_dim,\n",
    "        distance=models.Distance.COSINE,\n",
    "        on_disk=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add(\n",
    "    documents=chunks,\n",
    "    embeddings=embeddings,\n",
    "    metadata_keys=[\"source_file\", \"source_id\", \"title\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6f2b2144-2458-43ef-8674-2a58cd847ffb'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0].id_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = vector_store._client.retrieve(\n",
    "    collection_name=vector_store.collection_name,\n",
    "    ids=[chunks[0].id_],\n",
    "    with_vectors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6f2b2144-2458-43ef-8674-2a58cd847ffb\n",
      "{'source_id': '780f8c46-3ce0-4f03-8939-7c893b65ab1e', 'source_file': '★2019 제1회 증시콘서트 자료집_최종★.pdf'}\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "print(points[0].id)\n",
    "print(points[0].payload)\n",
    "print(len(points[0].vector))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docling",
   "language": "python",
   "name": "docling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
